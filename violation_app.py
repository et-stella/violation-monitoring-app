import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

st.set_page_config(page_title="ì»¤ë¨¸ì…œ ì •ì±… ìœ„ë°˜ íƒì§€ê¸°", page_icon="ğŸ›‘", layout="wide")
st.title("ğŸ›‘ ì»¤ë¨¸ì…œ ì •ì±… ìœ„ë°˜ íƒì§€ê¸°")
st.markdown("ê³ ê°ì˜ êµ¬ë§¤ ìˆ˜ëŸ‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì •ì±… ìœ„ë°˜ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="file_upload_1")

# ì¡°ê±´ í•¨ìˆ˜ ì •ì˜
def detect_condition_1(df):
    result = []
    for (sap, article), group in df.groupby(['SAPID', 'Article']):
        group = group.sort_values('PurchaseDate')
        last_date = group['PurchaseDate'].max()
        window = group[(group['PurchaseDate'] >= last_date - pd.Timedelta(days=365)) &
                       (group['PurchaseDate'] <= last_date)]
        qty = window['NetQuantity'].sum()
        if qty > 2:
            result.append({'SAPID': sap, 'Article': article, 'TotalQuantity': qty})
    return pd.DataFrame(result)

def detect_condition_2(df):
    result = []
    for sap, group in df.groupby('SAPID'):
        group = group.sort_values('PurchaseDate')
        last_date = group['PurchaseDate'].max()
        window = group[(group['PurchaseDate'] >= last_date - pd.Timedelta(days=30)) &
                       (group['PurchaseDate'] <= last_date)]
        article_counts = window.groupby('Article')['NetQuantity'].sum()
        valid_articles = article_counts[article_counts != 0]
        if valid_articles.count() > 5:
            for article, qty in valid_articles.items():
                result.append({'SAPID': sap, 'Article': article, 'TotalQuantity': qty})
    return pd.DataFrame(result)

def detect_condition_3(df):
    result = []
    for sap, group in df.groupby('SAPID'):
        group = group.sort_values('PurchaseDate')
        last_date = group['PurchaseDate'].max()
        window = group[(group['PurchaseDate'] >= last_date - pd.Timedelta(days=365)) &
                       (group['PurchaseDate'] <= last_date)]
        article_counts = window.groupby('Article')['NetQuantity'].sum()
        valid_articles = article_counts[article_counts != 0]
        if valid_articles.count() > 10:
            for article, qty in valid_articles.items():
                result.append({'SAPID': sap, 'Article': article, 'TotalQuantity': qty})
    return pd.DataFrame(result)

def detect_heavy_returners(df):
    return_df = df[df['NetQuantity'] < 0]
    return_summary = return_df.groupby(['SAPID', 'Article'])['NetQuantity'].sum().reset_index()
    return_summary['ReturnQty'] = return_summary['NetQuantity'].abs()
    total_purchase = df[df['NetQuantity'] > 0].groupby(['SAPID', 'Article'])['NetQuantity'].sum().reset_index()
    merged = pd.merge(return_summary, total_purchase, on=['SAPID', 'Article'], how='left', suffixes=('_Return', '_Purchase'))
    merged['ReturnRate'] = merged['ReturnQty'] / merged['NetQuantity_Purchase']
    merged = merged.drop(columns=['NetQuantity_Return', 'NetQuantity_Purchase'])
    merged = merged[merged['ReturnRate'].notna()].sort_values(by='ReturnQty', ascending=False)
    return merged

# ì‹¤í–‰
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    df['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'], errors='coerce')
    df['NetQuantity'] = pd.to_numeric(df['NetQuantity'], errors='coerce').fillna(0)

    required_cols = ['SAPID', 'Article', 'PurchaseDate', 'NetQuantity']
    if not all(col in df.columns for col in required_cols):
        st.error(f"â— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {required_cols}")
        st.stop()

    st.subheader("âœ… ì—…ë¡œë“œí•œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head())

    result1 = detect_condition_1(df)
    result2 = detect_condition_2(df)
    result3 = detect_condition_3(df)
    returners = detect_heavy_returners(df)

    if 'TotalQuantity' in result1.columns:
        result1 = result1.sort_values(by='TotalQuantity', ascending=False)
    if 'TotalQuantity' in result2.columns:
        result2 = result2.sort_values(by='TotalQuantity', ascending=False)
    if 'TotalQuantity' in result3.columns:
        result3 = result3.sort_values(by='TotalQuantity', ascending=False)

    # ëª¨ë“œ ì„ íƒ
    mode = st.selectbox("ğŸ§­ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["íƒì§€ ëª¨ë“œ", "ë¦¬í¬íŠ¸ ëª¨ë“œ"])

    if mode == "íƒì§€ ëª¨ë“œ":
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” ì¡°ê±´ 1", "ğŸ” ì¡°ê±´ 2", "ğŸ” ì¡°ê±´ 3", "â†©ï¸ ë¦¬í„´ ê³ ê°"])

        with tab1:
            st.markdown("**ì¡°ê±´ 1:** ë™ì¼ Articleì„ ë§ˆì§€ë§‰ êµ¬ë§¤ì¼ ê¸°ì¤€ 365ì¼ ë‚´ ìˆ˜ëŸ‰ 2ê°œ ì´ˆê³¼ êµ¬ë§¤")
            if 'SAPID' in result1.columns:
                selected_sapid = st.selectbox("ê³ ê° ì„ íƒ (ì¡°ê±´ 1)", result1['SAPID'].unique())
                st.dataframe(result1[result1['SAPID'] == selected_sapid])
            else:
                st.write("ìœ„ë°˜ ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab2:
            st.markdown("**ì¡°ê±´ 2:** ë§ˆì§€ë§‰ êµ¬ë§¤ì¼ ê¸°ì¤€ 30ì¼ ë‚´ ì„œë¡œ ë‹¤ë¥¸ Article 5ê°œ ì´ˆê³¼ êµ¬ë§¤")
            if 'SAPID' in result2.columns:
                selected_sapid = st.selectbox("ê³ ê° ì„ íƒ (ì¡°ê±´ 2)", result2['SAPID'].unique())
                st.dataframe(result2[result2['SAPID'] == selected_sapid])
            else:
                st.write("ìœ„ë°˜ ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab3:
            st.markdown("**ì¡°ê±´ 3:** ë§ˆì§€ë§‰ êµ¬ë§¤ì¼ ê¸°ì¤€ 365ì¼ ë‚´ ì„œë¡œ ë‹¤ë¥¸ Article 10ê°œ ì´ˆê³¼ êµ¬ë§¤")
            if 'SAPID' in result3.columns:
                selected_sapid = st.selectbox("ê³ ê° ì„ íƒ (ì¡°ê±´ 3)", result3['SAPID'].unique())
                st.dataframe(result3[result3['SAPID'] == selected_sapid])
            else:
                st.write("ìœ„ë°˜ ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab4:
            st.markdown("**ë¦¬í„´ì´ ë§ì€ ê³ ê° ìš”ì•½**")
            if not returners.empty:
                return_article_count = df[df['NetQuantity'] < 0].groupby('SAPID')['Article'].nunique()
                purchase_article_count = df[df['NetQuantity'] > 0].groupby('SAPID')['Article'].nunique()
                return_rate_by_sapid = (return_article_count / purchase_article_count).fillna(0)

                return_summary = returners.groupby('SAPID')['ReturnQty'].sum().reset_index()
                return_summary['ReturnRate'] = return_summary['SAPID'].map(return_rate_by_sapid)

                selected_sapid = st.selectbox("ê³ ê° ì„ íƒ (ë¦¬í„´)", return_summary['SAPID'].unique())
                st.dataframe(return_summary[return_summary['SAPID'] == selected_sapid])
            else:
                st.write("ë¦¬í„´ ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")

    elif mode == "ë¦¬í¬íŠ¸ ëª¨ë“œ":
        st.header("ğŸ“Š ë¦¬í¬íŠ¸ ëª¨ë“œ: ì›”ë³„ íŠ¸ë Œë“œ ìš”ì•½")

        df['Month'] = df['PurchaseDate'].dt.to_period('M').astype(str)

        monthly_return_qty = df[df['NetQuantity'] < 0].groupby('Month')['NetQuantity'].sum().abs()
        st.subheader("ğŸ“¦ ì›”ë³„ ì´ ë¦¬í„´ ìˆ˜ëŸ‰")
        st.bar_chart(monthly_return_qty)

        return_articles = df[df['NetQuantity'] < 0].groupby(['SAPID', 'Month'])['Article'].nunique()
        purchase_articles = df[df['NetQuantity'] > 0].groupby(['SAPID', 'Month'])['Article'].nunique()
        return_rate = (return_articles / purchase_articles).fillna(0).reset_index()
        avg_return_rate = return_rate.groupby('Month')[0].mean()
        st.subheader("ğŸ“ˆ ì›”ë³„ í‰ê·  ë¦¬í„´ìœ¨")
        st.line_chart(avg_return_rate)

        def compute_violation_rate(result_df, label):
            if result_df.empty:
                return pd.Series(dtype=float)
            temp = result_df.copy()
            temp = temp.merge(df[['Article', 'PurchaseDate']], on='Article', how='left')
            temp['Month'] = temp['PurchaseDate'].dt.to_period('M').astype(str)
            rate = temp.groupby('Month')['SAPID'].nunique() / df.groupby('Month')['SAPID'].nunique()
            return rate.rename(label)

        cond1_rate = compute_violation_rate(result1, 'ì¡°ê±´ 1')
        cond2_rate = compute_violation_rate(result2, 'ì¡°ê±´ 2')
        cond3_rate = compute_violation_rate(result3, 'ì¡°ê±´ 3')

        violation_df = pd.concat([cond1_rate, cond2_rate, cond3_rate], axis=1).fillna(0)

        st.subheader("ğŸ“‰ ì›”ë³„ ì¡°ê±´ë³„ ìœ„ë°˜ìœ¨")
        st.line_chart(violation_df)
else:
    st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
